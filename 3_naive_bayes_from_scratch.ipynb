{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply Bayes Rule to mutli-class document classfication <br> (from scratch)\n",
    "-----\n",
    "\n",
    "![](images/bayes_rule.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "Naive Bayes Classification Steps\n",
    "-------\n",
    "\n",
    "1. Get labeled data\n",
    "1. Preprocess\n",
    "1. Apply Mulitnomial Naive Bayes\n",
    "    1. Calculate document class priors\n",
    "    1. Calculate conditional probabilities of each word for each class\n",
    "    1. Calculate the proportional probabilities for each class of new document\n",
    "    1. Pick the winning class\n",
    "1. Evaluate with metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data & preprocess\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = namedtuple('data', 'id_num label tokens') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(id_num=42, label='cat', tokens=\"🐱 🐱 🐶 🐈 \".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [Data(42, 'cat',  \"🐈 🐯 🐱 🐩 🐱\".split()),\n",
    "         Data(43, 'dog',  \"🐶 🐶 🐈 🐶 🐩 🐈 🐶 🐶\".split()),\n",
    "         Data(45, 'cat',  \"🐈 🐈 🐯 🐶 🐈\".split()),\n",
    "         Data(45, 'cat',  \"🐈 🐈 🐈\".split()),\n",
    "         Data(48, 'dog',  \"🐶 🐶 🐯 🐈 🐩 🐱 🐩 🐶 🐩 🐶 \".split()),\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate document class priors\n",
    "---- \n",
    "\n",
    "$$P(c) = \\frac{N_c}{N}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat', 'dog'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What labels are we dealing with?\n",
    "labels = {d.label for d in train}\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many documents are dealing with?\n",
    "n_docs = len(train)\n",
    "n_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('cat', 0.6)\n",
      "('dog', 0.4)\n"
     ]
    }
   ],
   "source": [
    "# For each label, find the probability of baseline occurance\n",
    "doc_priors = defaultdict(float)\n",
    "\n",
    "for label in labels:\n",
    "    doc_priors[label] = sum(1 for d in train if d.label == label)/n_docs\n",
    "\n",
    "print(*doc_priors.items(), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate conditional probabilities of each word for each class\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab: ['🐈', '🐯', '🐱', '🐩', '🐱', '🐶', '🐶', '🐈', '🐶', '🐩', '🐈', '🐶', '🐶', '🐈', '🐈', '🐯', '🐶', '🐈', '🐈', '🐈', '🐈', '🐶', '🐶', '🐯', '🐈', '🐩', '🐱', '🐩', '🐶', '🐩', '🐶']\n"
     ]
    }
   ],
   "source": [
    "# Get all tokens, aka the vocabulary\n",
    "vocab = []\n",
    "\n",
    "for doc in train:\n",
    "    vocab.extend(doc.tokens)\n",
    "    \n",
    "print(\"Vocab:\", vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'🐈', '🐩', '🐯', '🐱', '🐶'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique tokens\n",
    "set(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cardinality of vocab: 5\n"
     ]
    }
   ],
   "source": [
    "# Number of unique tokens, cardinality\n",
    "v = len(set(vocab))\n",
    "print(\"Cardinality of vocab:\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'cat': defaultdict(float,\n",
       "                         {'🐈': 0.5384615384615384,\n",
       "                          '🐯': 0.15384615384615385,\n",
       "                          '🐱': 0.15384615384615385,\n",
       "                          '🐩': 0.07692307692307693,\n",
       "                          '🐶': 0.07692307692307693}),\n",
       "             'dog': defaultdict(float,\n",
       "                         {'🐈': 0.16666666666666666,\n",
       "                          '🐯': 0.05555555555555555,\n",
       "                          '🐱': 0.05555555555555555,\n",
       "                          '🐩': 0.2222222222222222,\n",
       "                          '🐶': 0.5})})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A default dict of default dicts; inner default dict is a probability\n",
    "cond_prob = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "for label in labels:\n",
    "    \n",
    "    label_tokens = []\n",
    "    for doc in train:\n",
    "         # For a given label, get a list of all the tokens for all the docs \n",
    "        if doc.label == label:\n",
    "            label_tokens.extend(doc.tokens)\n",
    "\n",
    "    for token in vocab:\n",
    "        # Find conditional probability: token count / total count\n",
    "        cond_prob[label][token] = label_tokens.count(token) / len(label_tokens) \n",
    "\n",
    "cond_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that each label is a pmf\n",
    "for label in labels:\n",
    "    assert round(sum(cond_prob[label].values())) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a new document without a label,  calculate the proportional probabilities for each class\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(c | X) = P(c) •  \\prod_{i=1}^n P(x_i | c)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from functools import reduce\n",
    "\n",
    "def  product(iterable):\n",
    "    return reduce(operator.mul, iterable, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('cat', 0.003550295857988166)\n",
      "('dog', 0.1)\n"
     ]
    }
   ],
   "source": [
    "# test = Data(id_num=90, label=None, tokens=\"🐱\".split())\n",
    "test = Data(id_num=91, label=None, tokens=\"🐶 🐶\".split()) \n",
    "# test = Data(id_num=92, label=None, tokens=\"🐶 🐱\".split())\n",
    "# test = Data(id_num=93, label=None, tokens=\"🐈 🐈 🐶 🐶 🐩 🐱 🐱\".split())\n",
    "# test = Data(id_num=94, label=None, tokens=\"🐬\".split()) # Out of sample prediction\n",
    "\n",
    "prob_predicted = defaultdict(float)\n",
    "for label in labels:\n",
    "    # For each label, calculate the conditional probability based on the prior and the tokens that appear\n",
    "    prob_predicted[label] = doc_priors[label] * product(cond_prob[label][t] for t in test.tokens)\n",
    "    \n",
    "print(*dict(prob_predicted).items(), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick the winning class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: cat\n"
     ]
    }
   ],
   "source": [
    "# Naive\n",
    "label, prob = max(prob_predicted.items(),\n",
    "                  key=itemgetter(1))\n",
    "print(\"The predicted class is:\", label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br> \n",
    "<br>\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: cat\n"
     ]
    }
   ],
   "source": [
    "# Handle ties and fall back to document priors if winning probability is zero\n",
    "label, prob = max(prob_predicted.items(),\n",
    "                  key=itemgetter(1))\n",
    "if prob > 0:\n",
    "    print(\"The predicted class is: \", end=\"\")\n",
    "    print(*(k for k, v in prob_predicted.items() if v == prob))\n",
    "else:\n",
    "    label, prob = max(doc_priors.items(),\n",
    "                      key=itemgetter(1))\n",
    "    print(\"The predicted class is:\", label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary\n",
    "------\n",
    "\n",
    "- Naive Bayes (NB) is a simple and powerful algorithm for text classification\n",
    "- To apply NB, follow a step-by-step process to calculate each probability\n",
    "- Python's Standard Library has helper functions to write elegant and performant code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br> \n",
    "<br>\n",
    "\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
